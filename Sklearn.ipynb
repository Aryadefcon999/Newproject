{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e7c5702",
   "metadata": {},
   "source": [
    "# Pipeline for Sklear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ccc2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris #This Load a data set  now we using the iris data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810bed50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split#This is use to split the  dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416308b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler#in this data set we are using the algorithms for the we use the Standerscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbb7367d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA#(Principal component analysis )that means we redus the dimensions of the\n",
    "#fetures eg we have 4 fetures we reduce the and make 2fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab4f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline#This help us to use to creat the pipeline process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc206af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression#this is all three algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6ce1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100747bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dbb1dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad7d4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb1442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we just split the data \n",
    "X_train,X_test,y_train,y_test=train_test_split(iris_df.data,iris_df.target,test_size=0.3,random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e398b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pipelines Creation \n",
    "#1. Data preprocessing by using the standard scale\n",
    "#2. Reduce the dimension using the PCA\n",
    "#3. Apply classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00bed88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first initial step is all about the pre-processing the data \n",
    "#The last pupil is basically the classification of algorithem that we have to do.\n",
    "#All the abject are diffirent so they work independently\n",
    "pipeline_lr=Pipeline([('scalar1',StandardScaler()),\n",
    "                     ('pca1',PCA(n_components=2)),\n",
    "                     ('lr_classifier',LogisticRegression(random_state=0))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcd524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_dt=Pipeline([('scalar2',StandardScaler()),\n",
    "                     ('pca2',PCA(n_components=2)),\n",
    "                     ('dt_classifier',DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b77e9677",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_randomforest=Pipeline([('scalar3',StandardScaler()),\n",
    "                     ('pca3',PCA(n_components=2)),\n",
    "                     ('rf_classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddd2dd",
   "metadata": {},
   "source": [
    "# Note\n",
    "We are calling the all three algorithem and see which one the best one and then we use that algorithem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00dd8894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We make all the pipeline is the list formate\n",
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_randomforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5de5029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are finding the best algorithem out this three\n",
    "best_accuracy=0.0#Which run the best it will come under this \n",
    "best_classification=0\n",
    "best_pipeline=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d11cb64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of pipeline and classification type for ease of reference\n",
    "pipe_dict = {0: 'Logistic Regression', 1: 'Decision Tree', 2: 'RandomForest'}\n",
    "\n",
    "# As soon as we use pipe.fit the fist 2 estimate is fit and transform and after that the final class algorithem basically do the set\n",
    "for pipe in pipelines:\n",
    "    pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "368993c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 0.8666666666666667\n",
      "Decision Tree 0.9111111111111111\n",
      "RandomForest 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "#We find the best accuracy \n",
    "for i,model in enumerate(pipelines):\n",
    "    print('{} {}'.format(pipe_dict[i],model.score(X_test,y_test)))\n",
    "    #the frist black {its hold the algorithem name and the  sec{hold the persentage }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfaae3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we find the best score \n",
    "for i,model in enumerate (pipelines):\n",
    "    if model.score (X_test,y_test)>best_accuracy:\n",
    "        best_accuracy=model.score(X_test,y_test)\n",
    "        best_pipeline=model\n",
    "        best_classification=i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3638ea90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score model is = Decision Tree\n"
     ]
    }
   ],
   "source": [
    "print('The best score model is = {}'.format(pipe_dict[best_classification]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e88002",
   "metadata": {},
   "source": [
    "# Pipelines Perform Hyperparameter Tuning Using Grid SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a23d7332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c27a84e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 2.78255940e+00, 7.74263683e+00, 2.15443469e+01,\n",
       "       5.99484250e+01, 1.66810054e+02, 4.64158883e+02, 1.29154967e+03,\n",
       "       3.59381366e+03, 1.00000000e+04])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf=np.logspace(0,4,10)\n",
    "ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5bc2648d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "50 fits failed out of a total of 1920.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.95238095        nan 0.94285714        nan 0.94285714        nan\n",
      " 0.97142857        nan 0.97142857        nan 0.96190476        nan\n",
      " 0.96190476        nan 0.96190476        nan 0.95238095        nan\n",
      " 0.95238095        nan 0.95238095 0.98095238 0.98095238 0.94285714\n",
      " 0.94285714 0.98095238 0.98095238 0.97142857 0.94285714 0.98095238\n",
      " 0.98095238 0.97142857 0.96190476 0.98095238 0.98095238 0.98095238\n",
      " 0.97142857 0.98095238 0.98095238 0.98095238 0.96190476 0.98095238\n",
      " 0.98095238 0.97142857 0.96190476 0.98095238 0.98095238 0.97142857\n",
      " 0.96190476 0.98095238 0.98095238 0.97142857 0.96190476 0.98095238\n",
      " 0.98095238 0.97142857 0.96190476 0.98095238 0.98095238 0.97142857\n",
      " 0.92380952 0.92380952 0.92380952 0.93333333 0.92380952 0.92380952\n",
      " 0.8952381  0.8952381  0.93333333 0.81904762 0.9047619  0.93333333\n",
      " 0.87619048 0.92380952 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.95238095 0.94285714 0.94285714 0.95238095 0.94285714 0.94285714\n",
      " 0.96190476 0.94285714 0.95238095 0.35238095 0.37142857 0.37142857\n",
      " 0.94285714 0.93333333 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.95238095 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.95238095 0.95238095 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.87619048 0.93333333 0.92380952 0.88571429 0.93333333 0.93333333\n",
      " 0.93333333 0.91428571 0.93333333 0.85714286 0.92380952 0.93333333\n",
      " 0.88571429 0.93333333 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.91428571 0.94285714 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.95238095 0.95238095 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.35238095 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.94285714 0.94285714\n",
      " 0.94285714 0.95238095 0.94285714 0.94285714 0.96190476 0.94285714\n",
      " 0.94285714 0.94285714 0.94285714 0.36190476 0.37142857 0.37142857\n",
      " 0.88571429 0.92380952 0.92380952 0.92380952 0.91428571 0.91428571\n",
      " 0.86666667 0.93333333 0.91428571 0.9047619  0.8952381  0.93333333\n",
      " 0.85714286 0.92380952 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.93333333 0.95238095 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.95238095 0.94285714 0.95238095\n",
      " 0.93333333 0.94285714 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.94285714 0.94285714 0.95238095\n",
      " 0.94285714 0.94285714 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.8952381  0.93333333 0.93333333 0.8952381  0.91428571 0.93333333\n",
      " 0.88571429 0.91428571 0.92380952 0.86666667 0.93333333 0.93333333\n",
      " 0.8952381  0.93333333 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.96190476 0.94285714 0.94285714\n",
      " 0.93333333 0.94285714 0.94285714 0.93333333 0.93333333 0.95238095\n",
      " 0.93333333 0.95238095 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.92380952 0.96190476 0.94285714\n",
      " 0.95238095 0.94285714 0.94285714 0.96190476 0.94285714 0.94285714\n",
      " 0.94285714 0.94285714 0.93333333 0.37142857 0.37142857 0.37142857\n",
      " 0.92380952 0.9047619  0.9047619  0.87619048 0.82857143 0.92380952\n",
      " 0.81904762 0.93333333 0.93333333 0.74285714 0.93333333 0.9047619\n",
      " 0.86666667 0.93333333 0.93333333 0.35238095 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.95238095 0.95238095 0.94285714\n",
      " 0.94285714 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.94285714 0.94285714 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.94285714 0.94285714 0.94285714\n",
      " 0.95238095 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.96190476 0.93333333 0.94285714 0.34285714 0.37142857 0.37142857\n",
      " 0.8952381  0.91428571 0.93333333 0.8        0.91428571 0.9047619\n",
      " 0.76190476 0.9047619  0.91428571 0.87619048 0.9047619  0.93333333\n",
      " 0.87619048 0.8952381  0.93333333 0.36190476 0.37142857 0.37142857\n",
      " 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714 0.94285714\n",
      " 0.93333333 0.95238095 0.95238095 0.95238095 0.95238095 0.94285714\n",
      " 0.95238095 0.93333333 0.94285714 0.37142857 0.37142857 0.37142857\n",
      " 0.93333333 0.94285714 0.94285714 0.96190476 0.94285714 0.94285714\n",
      " 0.96190476 0.94285714 0.94285714 0.94285714 0.95238095 0.94285714\n",
      " 0.94285714 0.94285714 0.93333333 0.35238095 0.37142857 0.37142857]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Ketan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline\n",
    "pipe = Pipeline([(\"classifier\", RandomForestClassifier())])\n",
    "# Create dictionary with candidate learning algorithms and their hyperparameters\n",
    "grid_param = [\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2','l1'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10)\n",
    "                 },\n",
    "                {\"classifier\": [LogisticRegression()],\n",
    "                 \"classifier__penalty\": ['l2'],\n",
    "                 \"classifier__C\": np.logspace(0, 4, 10),\n",
    "                 \"classifier__solver\":['newton-cg','saga','sag','liblinear'] ##This solvers don't allow L1 penalty\n",
    "                 },\n",
    "                {\"classifier\": [RandomForestClassifier()],\n",
    "                 \"classifier__n_estimators\": [10, 100, 1000],\n",
    "                 \"classifier__max_depth\":[5,8,15,25,30,None],\n",
    "                 \"classifier__min_samples_leaf\":[1,2,5,10,15,100],\n",
    "                 \"classifier__max_leaf_nodes\": [2, 5,10]}]\n",
    "# create a gridsearch of the pipeline, the fit the best model\n",
    "gridsearch = GridSearchCV(pipe, grid_param, cv=5, verbose=0,n_jobs=-1) # Fit grid search\n",
    "best_model = gridsearch.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d08f8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('classifier', LogisticRegression(solver='saga'))])\n",
      "The mean accuracy of the model is: 0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(best_model.best_estimator_)\n",
    "print(\"The mean accuracy of the model is:\",best_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bc68e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
